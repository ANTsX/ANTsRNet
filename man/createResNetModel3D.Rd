% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/createResNetModel.R
\name{createResNetModel3D}
\alias{createResNetModel3D}
\title{3-D implementation of the ResNet deep learning architecture.}
\usage{
createResNetModel3D(
  inputImageSize,
  inputScalarsSize = 0,
  numberOfClassificationLabels = 1000,
  layers = 1:4,
  residualBlockSchedule = c(3, 4, 6, 3),
  lowestResolution = 64,
  cardinality = 1,
  squeezeAndExcite = FALSE,
  mode = "classification"
)
}
\arguments{
\item{inputImageSize}{Used for specifying the input tensor shape.  The
shape (or dimension) of that tensor is the image dimensions followed by
the number of channels (e.g., red, green, and blue).  The batch size
(i.e., number of training images) is not specified a priori.}

\item{inputScalarsSize}{Optional integer specifying the size of the input
vector for scalars that get concatenated to the fully connected layer at
the end of the network.}

\item{numberOfClassificationLabels}{Number of segmentation labels.}

\item{layers}{a vector determining the number of 'filters' defined at
for each layer.}

\item{residualBlockSchedule}{vector defining the how many residual blocks
repeats.}

\item{lowestResolution}{number of filters at the initial layer.}

\item{cardinality}{perform  ResNet (cardinality = 1) or ResNeXt
(cardinality != 1 but powers of 2---try '32' )}

\item{squeezeAndExcite}{boolean to add the squeeze-and-excite block variant.}

\item{mode}{'classification' or 'regression'.  Default = 'classification'.}
}
\value{
an ResNet keras model
}
\description{
Creates a keras model of the ResNet deep learning architecture for image
classification.  The paper is available here:
}
\details{
\preformatted{    https://arxiv.org/abs/1512.03385
}

This particular implementation was influenced by the following python
implementation:\preformatted{    https://gist.github.com/mjdietzx/0cb95922aac14d446a6530f87b3a04ce
}
}
\examples{

\dontrun{

library( ANTsRNet )
library( keras )

mnistData <- dataset_mnist()
numberOfLabels <- 10

# Extract a small subset for something that can run quickly

X_trainSmall <- mnistData$train$x[1:10,,]
X_trainSmall <- array( data = X_trainSmall, dim = c( dim( X_trainSmall ), 1 ) )
Y_trainSmall <- to_categorical( mnistData$train$y[1:10], numberOfLabels )

X_testSmall <- mnistData$test$x[1:10,,]
X_testSmall <- array( data = X_testSmall, dim = c( dim( X_testSmall ), 1 ) )
Y_testSmall <- to_categorical( mnistData$test$y[1:10], numberOfLabels )

# We add a dimension of 1 to specify the channel size

inputImageSize <- c( dim( X_trainSmall )[2:3], 1 )

model <- createResNetModel2D( inputImageSize = inputImageSize,
  numberOfClassificationLabels = numberOfLabels )

model \%>\% compile( loss = 'categorical_crossentropy',
  optimizer = optimizer_adam( lr = 0.0001 ),
  metrics = c( 'categorical_crossentropy', 'accuracy' ) )

track <- model \%>\% fit( X_trainSmall, Y_trainSmall, verbose = 1,
  epochs = 1, batch_size = 2, shuffle = TRUE, validation_split = 0.5 )

# Now test the model

testingMetrics <- model \%>\% evaluate( X_testSmall, Y_testSmall )
predictedData <- model \%>\% predict( X_testSmall, verbose = 1 )

}
}
\author{
Tustison NJ
}
