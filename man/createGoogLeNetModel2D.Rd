% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/createGoogLeNetModel.R
\name{createGoogLeNetModel2D}
\alias{createGoogLeNetModel2D}
\title{2-D implementation of the GoogLeNet deep learning architecture.}
\usage{
createGoogLeNetModel2D(inputImageSize,
  numberOfClassificationLabels = 1000, mode = "classification")
}
\arguments{
\item{inputImageSize}{Used for specifying the input tensor shape.  The
shape (or dimension) of that tensor is the image dimensions followed by
the number of channels (e.g., red, green, and blue).  The batch size
(i.e., number of training images) is not specified a priori.}

\item{numberOfClassificationLabels}{Number of segmentation labels.}

\item{mode}{'classification' or 'regression'.  Default = 'classification'.}
}
\value{
a GoogLeNet keras model
}
\description{
Creates a keras model of the GoogLeNet deep learning architecture for image
recognition based on the paper
}
\details{
C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov, D. Erhan, V. Vanhoucke,
A. Rabinovich, Going Deeper with Convolutions
C. Szegedy, V. Vanhoucke, S. Ioffe, J. Shlens, and Z. Wojna. Rethinking the Inception
Architecture for Computer Vision

available here:

https://arxiv.org/abs/1409.4842
https://arxiv.org/abs/1512.00567

This particular implementation was influenced by the following python
implementation:

https://github.com/fchollet/deep-learning-models/blob/master/inception_v3.py
}
\examples{

library( ANTsRNet )
library( keras )

mnistData <- dataset_mnist()
numberOfLabels <- 10

# Extract a small subset for something that can run quickly

X_trainSmall <- mnistData$train$x[1:10,,]
X_trainSmall <- array( data = X_trainSmall, dim = c( dim( X_trainSmall ), 1 ) )
Y_trainSmall <- to_categorical( mnistData$train$y[1:10], numberOfLabels )

X_testSmall <- mnistData$test$x[1:10,,]
X_testSmall <- array( data = X_testSmall, dim = c( dim( X_testSmall ), 1 ) )
Y_testSmall <- to_categorical( mnistData$test$y[1:10], numberOfLabels )

# We add a dimension of 1 to specify the channel size

inputImageSize <- c( dim( X_trainSmall )[2:3], 1 )

model <- createGoogLeNetModel2D( inputImageSize = inputImageSize,
  numberOfClassificationLabels = numberOfLabels )

model \%>\% compile( loss = 'categorical_crossentropy',
  optimizer = optimizer_adam( lr = 0.0001 ),
  metrics = c( 'categorical_crossentropy', 'accuracy' ) )

# Comment out the rest due to travis build constraints

# track <- model \%>\% fit( X_trainSmall, Y_trainSmall, verbose = 1,
#   epochs = 1, batch_size = 2, shuffle = TRUE, validation_split = 0.5 )

# Now test the model

# testingMetrics <- model \%>\% evaluate( X_testSmall, Y_testSmall )
# predictedData <- model \%>\% predict( X_testSmall, verbose = 1 )

}
\author{
Tustison NJ
}
