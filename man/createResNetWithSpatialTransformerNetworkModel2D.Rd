% Generated by roxygen2: do not edit by hand
% Please edit documentation in
%   R/createResNetWithSpatialTransformerNetworkModel.R
\name{createResNetWithSpatialTransformerNetworkModel2D}
\alias{createResNetWithSpatialTransformerNetworkModel2D}
\title{2-D implementation of the ResNet deep learning architecture with a
preceding spatial transformer network layer.}
\usage{
createResNetWithSpatialTransformerNetworkModel2D(
  inputImageSize,
  numberOfClassificationLabels = 1000,
  layers = 1:4,
  residualBlockSchedule = c(3, 4, 6, 3),
  lowestResolution = 64,
  cardinality = 1,
  numberOfSpatialTransformerUnits = 50,
  resampledSize = c(64, 64),
  mode = "classification"
)
}
\arguments{
\item{inputImageSize}{Used for specifying the input tensor shape.  The
shape (or dimension) of that tensor is the image dimensions followed by
the number of channels (e.g., red, green, and blue).  The batch size
(i.e., number of training images) is not specified a priori.}

\item{numberOfClassificationLabels}{Number of segmentation labels.}

\item{layers}{a vector determining the number of 'filters' defined at
for each layer.}

\item{residualBlockSchedule}{vector defining the how many residual blocks
repeats.}

\item{lowestResolution}{number of filters at the initial layer.}

\item{cardinality}{perform  ResNet (cardinality = 1) or ResNeXt
(cardinality != 1 but powers of 2---try '32' )}

\item{numberOfSpatialTransformerUnits}{number of units in the dense layer.}

\item{resampledSize}{output image size of the spatial transformer network.}

\item{mode}{'classification' or 'regression'.  Default = 'classification'.}
}
\value{
an STN + ResNet keras model
}
\description{
Creates a keras model of the ResNet deep learning architecture for image
classification with a spatial transformer network (STN) layer.  The paper
is available here:
}
\details{
\preformatted{    https://arxiv.org/abs/1512.03385
}
}
\examples{

\dontrun{
library( ANTsRNet )
library( keras )

mnistData <- dataset_mnist()
numberOfLabels <- 10

# Extract a small subset for something that can run quickly

X_trainSmall <- mnistData$train$x[1:10,,]
X_trainSmall <- array( data = X_trainSmall, dim = c( dim( X_trainSmall ), 1 ) )
Y_trainSmall <- to_categorical( mnistData$train$y[1:10], numberOfLabels )

X_testSmall <- mnistData$test$x[1:10,,]
X_testSmall <- array( data = X_testSmall, dim = c( dim( X_testSmall ), 1 ) )
Y_testSmall <- to_categorical( mnistData$test$y[1:10], numberOfLabels )

# We add a dimension of 1 to specify the channel size

inputImageSize <- c( dim( X_trainSmall )[2:3], 1 )

model <- createResNetWithSpatialTransformerNetworkModel2D(
  inputImageSize = inputImageSize,
  numberOfClassificationLabels = numberOfLabels )

model \%>\% compile( loss = 'categorical_crossentropy',
  optimizer = optimizer_adam( lr = 0.0001 ),
  metrics = c( 'categorical_crossentropy', 'accuracy' ) )

# Comment out the rest due to travis build constraints

# track <- model \%>\% fit( X_trainSmall, Y_trainSmall, verbose = 1,
#   epochs = 1, batch_size = 2, shuffle = TRUE, validation_split = 0.5 )

# Now test the model

# testingMetrics <- model \%>\% evaluate( X_testSmall, Y_testSmall )
# predictedData <- model \%>\% predict( X_testSmall, verbose = 1 )
rm(model); gc()
}
}
\author{
Tustison NJ
}
