% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/createVggModel.R
\name{createVggModel2D}
\alias{createVggModel2D}
\title{2-D implementation of the VGG deep learning architecture.}
\usage{
createVggModel2D(
  inputImageSize,
  numberOfClassificationLabels = 1000,
  layers = c(1, 2, 3, 4, 4),
  lowestResolution = 64,
  convolutionKernelSize = c(3, 3),
  poolSize = c(2, 2),
  strides = c(2, 2),
  numberOfDenseUnits = 4096,
  dropoutRate = 0,
  style = 19,
  mode = "classification"
)
}
\arguments{
\item{inputImageSize}{Used for specifying the input tensor shape.  The
shape (or dimension) of that tensor is the image dimensions followed by
the number of channels (e.g., red, green, and blue).  The batch size
(i.e., number of training images) is not specified a priori.}

\item{numberOfClassificationLabels}{Number of segmentation labels.}

\item{layers}{a vector determining the number of filters defined at
for each layer.}

\item{lowestResolution}{number of filters at the beginning.}

\item{convolutionKernelSize}{2-d vector definining the kernel size
during the encoding path}

\item{poolSize}{2-d vector defining the region for each pooling layer.}

\item{strides}{2-d vector describing the stride length in each direction.}

\item{numberOfDenseUnits}{integer for the number of units in the last layers.}

\item{dropoutRate}{float between 0 and 1 to use between dense layers.}

\item{style}{\verb{'16'} or \verb{'19'} for VGG16 or VGG19, respectively.}

\item{mode}{'classification' or 'regression'.  Default = 'classification'.}
}
\value{
a VGG keras model
}
\description{
Creates a keras model of the Vgg deep learning architecture for image
recognition based on the paper
}
\details{
K. Simonyan and A. Zisserman, Very Deep Convolutional Networks for
Large-Scale Image Recognition

available here:\preformatted{    \url{https://arxiv.org/abs/1409.1556}
}

This particular implementation was influenced by the following python
implementation:\preformatted{    \url{https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d}
}
}
\examples{

library( ANTsRNet )
library( keras )
library( ANTsR )

mnistData <- dataset_mnist()
numberOfLabels <- 10

# Extract a small subset for something that can run quickly.
# We also need to resample since the native mnist data size does
# not fit with GoogLeNet parameters.

resampledImageSize <- c( 100, 100 )
numberOfTrainingData <- 10
numberOfTestingData <- 5

X_trainSmall <- as.array(
  resampleImage( as.antsImage( mnistData$train$x[1:numberOfTrainingData,,] ),
    c( numberOfTrainingData, resampledImageSize ), TRUE ) )
X_trainSmall <- array( data = X_trainSmall, dim = c( dim( X_trainSmall ), 1 ) )
Y_trainSmall <- to_categorical( mnistData$train$y[1:numberOfTrainingData], numberOfLabels )

X_testSmall <- as.array(
  resampleImage( as.antsImage( mnistData$test$x[1:numberOfTestingData,,] ),
    c( numberOfTestingData, resampledImageSize ), TRUE ) )
X_testSmall <- array( data = X_testSmall, dim = c( dim( X_testSmall ), 1 ) )
Y_testSmall <- to_categorical( mnistData$test$y[1:numberOfTestingData], numberOfLabels )

# We add a dimension of 1 to specify the channel size

inputImageSize <- c( dim( X_trainSmall )[2:3], 1 )

model <- createVggModel2D( inputImageSize = c( resampledImageSize, 1 ),
  numberOfClassificationLabels = numberOfLabels )

model \%>\% compile( loss = 'categorical_crossentropy',
  optimizer = optimizer_adam( lr = 0.0001 ),
  metrics = c( 'categorical_crossentropy', 'accuracy' ) )

# Comment out the rest due to travis build constraints

# track <- model \%>\% fit( X_trainSmall, Y_trainSmall, verbose = 1,
#   epochs = 1, batch_size = 2, shuffle = TRUE, validation_split = 0.5 )

# Now test the model

# testingMetrics <- model \%>\% evaluate( X_testSmall, Y_testSmall )
# predictedData <- model \%>\% predict( X_testSmall, verbose = 1 )

}
\author{
Tustison NJ
}
