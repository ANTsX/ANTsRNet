<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>2-D implementation of the U-net deep learning architecture. — createUnetModel2D • ANTsRNet</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- sticky kit -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



<meta property="og:title" content="2-D implementation of the U-net deep learning architecture. — createUnetModel2D" />

<meta property="og:description" content="Creates a keras model of the U-net deep learning architecture for image
segmentation.  More information is provided at the authors' website:" />
<meta name="twitter:card" content="summary" />



<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">ANTsRNet</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>2-D implementation of the U-net deep learning architecture.</h1>
    
    <div class="hidden name"><code>createUnetModel2D.Rd</code></div>
    </div>

    <div class="ref-description">
    
    <p>Creates a keras model of the U-net deep learning architecture for image
segmentation.  More information is provided at the authors' website:</p>
    
    </div>

    <pre class="usage"><span class='fu'>createUnetModel2D</span>(<span class='no'>inputImageSize</span>, <span class='kw'>numberOfOutputs</span> <span class='kw'>=</span> <span class='fl'>1</span>,
  <span class='kw'>numberOfLayers</span> <span class='kw'>=</span> <span class='fl'>4</span>, <span class='kw'>numberOfFiltersAtBaseLayer</span> <span class='kw'>=</span> <span class='fl'>32</span>,
  <span class='kw'>convolutionKernelSize</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>3</span>, <span class='fl'>3</span>), <span class='kw'>deconvolutionKernelSize</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>2</span>, <span class='fl'>2</span>),
  <span class='kw'>poolSize</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>2</span>, <span class='fl'>2</span>), <span class='kw'>strides</span> <span class='kw'>=</span> <span class='fu'>c</span>(<span class='fl'>2</span>, <span class='fl'>2</span>), <span class='kw'>dropoutRate</span> <span class='kw'>=</span> <span class='fl'>0</span>,
  <span class='kw'>mode</span> <span class='kw'>=</span> <span class='st'>"classification"</span>)</pre>
    
    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>inputImageSize</th>
      <td><p>Used for specifying the input tensor shape.  The
shape (or dimension) of that tensor is the image dimensions followed by
the number of channels (e.g., red, green, and blue).  The batch size
(i.e., number of training images) is not specified a priori.</p></td>
    </tr>
    <tr>
      <th>numberOfOutputs</th>
      <td><p>Meaning depends on the <code>mode</code>.  For
'classification' this is the number of segmentation labels.  For 'regression'
this is the number of outputs.</p></td>
    </tr>
    <tr>
      <th>numberOfLayers</th>
      <td><p>number of encoding/decoding layers.</p></td>
    </tr>
    <tr>
      <th>numberOfFiltersAtBaseLayer</th>
      <td><p>number of filters at the beginning and end
of the <code>'U'</code>.  Doubles at each descending/ascending layer.</p></td>
    </tr>
    <tr>
      <th>convolutionKernelSize</th>
      <td><p>2-d vector defining the kernel size
during the encoding path</p></td>
    </tr>
    <tr>
      <th>deconvolutionKernelSize</th>
      <td><p>2-d vector defining the kernel size
during the decoding</p></td>
    </tr>
    <tr>
      <th>poolSize</th>
      <td><p>2-d vector defining the region for each pooling layer.</p></td>
    </tr>
    <tr>
      <th>strides</th>
      <td><p>2-d vector describing the stride length in each direction.</p></td>
    </tr>
    <tr>
      <th>dropoutRate</th>
      <td><p>float between 0 and 1 to use between dense layers.</p></td>
    </tr>
    <tr>
      <th>mode</th>
      <td><p>'classification' or 'regression'.  Default = 'classification'.</p></td>
    </tr>
    </table>
    
    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>a u-net keras model to be used with subsequent fitting</p>
    
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p><a href='https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/'>https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/</a></p>
<p>with the paper available here:</p>
<p><a href='https://arxiv.org/abs/1505.04597'>https://arxiv.org/abs/1505.04597</a></p>
<p>This particular implementation was influenced by the following python
implementation:</p>
<p><a href='https://github.com/joelthelion/ultrasound-nerve-segmentation'>https://github.com/joelthelion/ultrasound-nerve-segmentation</a></p>
    

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'># Simple examples, must run successfully and quickly. These will be tested.
</div># NOT RUN {
 library( ANTsR )

 imageIDs <- c( "r16", "r27", "r30", "r62", "r64", "r85" )

 # Perform simple 3-tissue segmentation.  For convenience we are going

 segmentationLabels <- c( 1, 2, 3 )
 numberOfLabels <- length( segmentationLabels )

 images <- list()
 kmeansSegs <- list()

 trainingImageArrays <- list()
 trainingMaskArrays <- list()

 for( i in 1:length( imageIDs ) )
   {
   cat( "Processing image", imageIDs[i], "\n" )
   images[[i]] <- antsImageRead( getANTsRData( imageIDs[i] ) )
   mask <- getMask( images[[i]] )
   kmeansSegs[[i]] <- kmeansSegmentation( images[[i]],
     length( segmentationLabels ), mask, mrf = 0.0 )$segmentation

   trainingImageArrays[[i]] <- as.array( images[[i]] )
   trainingMaskArrays[[i]] <- as.array( mask )
   }

 # Reshape the training data to the format expected by keras

 trainingLabelData <- abind( trainingMaskArrays, along = 3 )
 trainingLabelData <- aperm( trainingLabelData, c( 3, 1, 2 ) )

 trainingData <- abind( trainingImageArrays, along = 3 )
 trainingData <- aperm( trainingData, c( 3, 1, 2 ) )

 # Perform a simple normalization which is important for U-net.
 # Other normalization methods might further improve results.

 trainingData <- ( trainingData - mean( trainingData ) ) / sd( trainingData )
 X_train <- array( trainingData, dim = c( dim( trainingData ), 1 ) )

 trainingLabelData <- abind( trainingMaskArrays, along = 3 )
 trainingLabelData <- aperm( trainingLabelData, c( 3, 1, 2 ) )
 Y_train <- encodeUnet( trainingLabelData, segmentationLabels )

 # Create the model

 unetModel <- createUnetModel2D( c( dim( trainingImageArrays[[1]] ), 1 ),
   numberOfOutputs = numberOfLabels )

 unetModel %>% compile( loss = loss_multilabel_dice_coefficient_error,
   optimizer = optimizer_adam( lr = 0.0001 ),
   metrics = c( multilabel_dice_coefficient ) )

 # Fit the model

 track <- unetModel %>% fit( X_train, Y_train,
                epochs = 100, batch_size = 32, verbose = 1, shuffle = TRUE,
                callbacks = list(
                  callback_model_checkpoint( paste0( baseDirectory, "weights.h5" ),
                     monitor = 'val_loss', save_best_only = TRUE ),
                  callback_reduce_lr_on_plateau( monitor = "val_loss", factor = 0.1 )
                ),
                validation_split = 0.2 )

 # Save the model and/or save the model weights

 save_model_hdf5( unetModel, filepath = 'unetModel.h5' )
 save_model_weights_hdf5( unetModel, filepath = 'unetModelWeights.h5' ) )
# }
</pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
    <h2>Contents</h2>
    <ul class="nav nav-pills nav-stacked">
      <li><a href="#arguments">Arguments</a></li>
      
      <li><a href="#value">Value</a></li>

      <li><a href="#details">Details</a></li>
      
      <li><a href="#examples">Examples</a></li>
    </ul>

    <h2>Author</h2>
    
Tustison NJ

  </div>
</div>

      <footer>
      <div class="copyright">
  <p>Developed by Nicholas J Tustison, Brian B Avants.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  

  </body>
</html>

